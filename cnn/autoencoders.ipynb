{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import idx2numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST_DIR = \"/content/m_nist/\"\n",
    "MNIST_DIR = \"../mnist/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = idx2numpy.convert_from_file(MNIST_DIR + \"train-images-idx3-ubyte\")\n",
    "print(train_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_flattened = train_arr.reshape(60000, -1)\n",
    "print(train_dataset_flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(train_dataset_flattened), np.min(train_dataset_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_flattened = train_dataset_flattened / 255.0\n",
    "print(np.max(train_dataset_flattened), np.min(train_dataset_flattened))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FC Auto Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(784,)),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoder(train_dataset_flattened[:5])\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(784, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "decoded = decoder(encoded)\n",
    "print(decoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder_fc = tf.keras.Sequential([encoder, decoder])\n",
    "dummy_images = auto_encoder_fc(train_dataset_flattened[:5])\n",
    "print(dummy_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder_fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder_fc.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = auto_encoder_fc.fit(\n",
    "    train_dataset_flattened, train_dataset_flattened,\n",
    "    batch_size=64,\n",
    "    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Train Loss\")\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(original_images, decoded_iamges):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.box(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img_idx = 0\n",
    "    for i in np.arange(1, 9, 2):\n",
    "        original_image = original_images[img_idx].reshape((28, 28))\n",
    "        decoded_image = decoded_iamges[img_idx].reshape((28, 28))\n",
    "        plt.subplot(4, 2, i)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(original_image, cmap=\"gray\")\n",
    "        plt.subplot(4, 2, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(decoded_image, cmap=\"gray\")\n",
    "        img_idx += 1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = train_dataset_flattened[:4]\n",
    "decoded_image_batch = auto_encoder_fc.predict(img_batch)\n",
    "print(img_batch. shape, decoded_image_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(img_batch, decoded_image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder_fc.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_images = auto_encoder_fc.layers[0](img_batch)\n",
    "print(compressed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_images = auto_encoder_fc.layers[1](compressed_images)\n",
    "show_images(img_batch, decoded_image_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet Auto Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_arr.shape)\n",
    "print(np.max(train_arr), np.min(train_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_2D = train_arr / 255.0\n",
    "print(train_dataset_2D.shape)\n",
    "train_dataset_2D = np.expand_dims(train_dataset_2D, axis=3)\n",
    "print(train_dataset_2D.shape)\n",
    "print(np.max(train_dataset_2D), np.min(train_dataset_2D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_conv = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(8, 3, strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(16, 3, strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(32, 5, activation=\"linear\")\n",
    "])\n",
    "\n",
    "dummy_batch = train_dataset_2D[:64]\n",
    "print(dummy_batch.shape)\n",
    "dummy_2D_encoded = encoder_conv(dummy_batch)\n",
    "print(dummy_2D_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_conv = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2DTranspose(32, 5, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(16, 3, strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(8, 3, strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(1, 2, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "dummy_2D_decoded = decoder_conv(dummy_2D_encoded)\n",
    "print(dummy_2D_decoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder_conv = tf.keras.Sequential([encoder_conv, decoder_conv])\n",
    "dummy_images = auto_encoder_conv(dummy_batch)\n",
    "print(dummy_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder_conv.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = auto_encoder_conv.fit(\n",
    "    train_dataset_2D, train_dataset_2D,\n",
    "    batch_size=64,\n",
    "    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Train Loss\")\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images = train_dataset_2D[:64]\n",
    "restored_images = auto_encoder_conv(original_images)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.box(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "img_idx = 0\n",
    "for i in np.arange(1, 9, 2):\n",
    "    original_image = original_images[img_idx].squeeze()\n",
    "    decoded_image = restored_images[img_idx].numpy().squeeze()\n",
    "    plt.subplot(4, 2, i)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(original_image, cmap=\"gray\")\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(decoded_image, cmap=\"gray\")\n",
    "    img_idx += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
